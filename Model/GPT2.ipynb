{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cvSUikEJOL3","outputId":"76f751b6-61f0-4d5d-d0ac-24d75749315d","executionInfo":{"status":"ok","timestamp":1686807175093,"user_tz":-540,"elapsed":12170,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.28.0\n","  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.0)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.28.0\n"]}],"source":["!pip install transformers==4.28.0"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTQsUbO1fbnJ","executionInfo":{"status":"ok","timestamp":1686807180428,"user_tz":-540,"elapsed":5346,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"cc244753-926a-481c-bb67-2d854b5e24ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting accelerate\n","  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.20.3\n"]}],"source":["!pip install --upgrade accelerate"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zlxc758cin2w","executionInfo":{"status":"ok","timestamp":1686807197156,"user_tz":-540,"elapsed":16734,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"a776ee14-fea0-4493-d8e5-36bedee50f53"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uDXAxpScI3RM","executionInfo":{"status":"ok","timestamp":1686807197594,"user_tz":-540,"elapsed":448,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re"]},{"cell_type":"markdown","source":["# 1. 데이터 불러오기"],"metadata":{"id":"7N2ylhRxgMiV"}},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"opapKwbnI51e","outputId":"6c1caeee-0fee-4cd6-dba8-30997586a717","executionInfo":{"status":"ok","timestamp":1686808690122,"user_tz":-540,"elapsed":1769,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            sentence  label  senti\n","0  Would be super sexy if you are only about 4 ft...      1      1\n","1  I'm 5'5\" and this barely stretched to the unde...      1      2\n","2                                 Don't waste your $      3      2\n","3                       Tiny fit and terrible print!      1      2\n","4  Got it for my brother who normally wears a large.      1      2"],"text/html":["\n","  <div id=\"df-cda7c7ac-5845-4d37-b04d-1134c16f70d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","      <th>senti</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Would be super sexy if you are only about 4 ft...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I'm 5'5\" and this barely stretched to the unde...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Don't waste your $</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Tiny fit and terrible print!</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Got it for my brother who normally wears a large.</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cda7c7ac-5845-4d37-b04d-1134c16f70d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cda7c7ac-5845-4d37-b04d-1134c16f70d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cda7c7ac-5845-4d37-b04d-1134c16f70d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":44}],"source":["df = pd.read_csv(\"/content/drive/MyDrive/TM/Data/Labeled.csv\", index_col = 0)\n","df.head()"]},{"cell_type":"code","source":["df.groupby('senti').count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"5VTFOCXwog-Z","executionInfo":{"status":"ok","timestamp":1686808764742,"user_tz":-540,"elapsed":14,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"d0d06155-6021-4d62-81cd-2216b5db52ae"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       sentence   label\n","senti                  \n","0          3275    3275\n","1        122532  122532\n","2        120204  120204"],"text/html":["\n","  <div id=\"df-d5098aa9-02a5-470d-a681-cf524b727c19\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>senti</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3275</td>\n","      <td>3275</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>122532</td>\n","      <td>122532</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>120204</td>\n","      <td>120204</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5098aa9-02a5-470d-a681-cf524b727c19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d5098aa9-02a5-470d-a681-cf524b727c19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d5098aa9-02a5-470d-a681-cf524b727c19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["df = df[df['senti'] != 0]"],"metadata":{"id":"otzu_5ZZo0CM","executionInfo":{"status":"ok","timestamp":1686808788449,"user_tz":-540,"elapsed":276,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acrQP30_o6Fs","executionInfo":{"status":"ok","timestamp":1686808945735,"user_tz":-540,"elapsed":256,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"654cb71a-8dee-4b21-f0ca-f53fdac3213d"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 242736 entries, 0 to 246010\n","Data columns (total 3 columns):\n"," #   Column    Non-Null Count   Dtype \n","---  ------    --------------   ----- \n"," 0   sentence  242736 non-null  object\n"," 1   label     242736 non-null  int64 \n"," 2   senti     242736 non-null  int64 \n","dtypes: int64(2), object(1)\n","memory usage: 7.4+ MB\n"]}]},{"cell_type":"code","source":["df0_1 = df.loc[(df['label'] == 0) & (df['senti'] == 1)] #delivery\n","df0_2 = df.loc[(df['label']==0) & (df['senti'] == 2)] #delivery\n","df1_1 = df.loc[(df['label']==1) & (df['senti'] == 1)] #size\n","df1_2 = df.loc[(df['label']==1) & (df['senti'] == 2)] #size\n","df2_1 = df.loc[(df['label']==2) & (df['senti'] == 1)] #color\n","df2_2 = df.loc[(df['label']==2) &  (df['senti'] == 2)] #color\n","df3_1 = df.loc[(df['label']==3) & (df['senti'] == 1)] #quality\n","df3_2 = df.loc[(df['label']==3) &  (df['senti'] == 2)] #quality"],"metadata":{"id":"NYq5cEejoafU","executionInfo":{"status":"ok","timestamp":1686809060015,"user_tz":-540,"elapsed":257,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["# 2. 데이터 전처리"],"metadata":{"id":"wmhNzqx6gOcH"}},{"cell_type":"code","execution_count":57,"metadata":{"id":"tsfQ1draI3s0","executionInfo":{"status":"ok","timestamp":1686809064690,"user_tz":-540,"elapsed":253,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["def cleaning(s):\n","    s = str(s)\n","    s = re.sub('\\s\\W',' ',s)\n","    s = re.sub('\\W,\\s',' ',s)\n","    s = re.sub(\"\\d+\", \"\", s)\n","    s = re.sub('\\s+',' ',s)\n","    s = re.sub('[!@#$_]', '', s)\n","    s = s.replace(\"co\",\"\")\n","    s = s.replace(\"https\",\"\")\n","    s = s.replace(\"[\\w*\",\" \")\n","    return s"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"BiSb-pOuJJuQ","executionInfo":{"status":"ok","timestamp":1686809121625,"user_tz":-540,"elapsed":344,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_delivery_pos.txt', 'w')\n","for idx, item in df0_1.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"]},{"cell_type":"code","source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_delivery_neg.txt', 'w')\n","for idx, item in df0_2.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"],"metadata":{"id":"G4djz-SlqJvO","executionInfo":{"status":"ok","timestamp":1686809138236,"user_tz":-540,"elapsed":4,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","execution_count":60,"metadata":{"id":"sZPCeCCFfbnL","executionInfo":{"status":"ok","timestamp":1686809163058,"user_tz":-540,"elapsed":2513,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_size_pos.txt', 'w')\n","for idx, item in df1_1.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"]},{"cell_type":"code","source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_size_neg.txt', 'w')\n","for idx, item in df1_2.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"],"metadata":{"id":"fbw50Mb0qUFr","executionInfo":{"status":"ok","timestamp":1686809195651,"user_tz":-540,"elapsed":7668,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","execution_count":62,"metadata":{"id":"cf0tC1QFfbnM","executionInfo":{"status":"ok","timestamp":1686809202812,"user_tz":-540,"elapsed":1020,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_color_pos.txt', 'w')\n","for idx, item in df2_1.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"]},{"cell_type":"code","source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_color_neg.txt', 'w')\n","for idx, item in df2_2.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"],"metadata":{"id":"8zVXxICZqdqR","executionInfo":{"status":"ok","timestamp":1686809214214,"user_tz":-540,"elapsed":500,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","execution_count":64,"metadata":{"id":"y4YlQTXefbnM","executionInfo":{"status":"ok","timestamp":1686809234440,"user_tz":-540,"elapsed":3998,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_quality_pos.txt', 'w')\n","for idx, item in df3_1.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"]},{"cell_type":"code","source":["text_data = open('/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_quality_neg.txt', 'w')\n","for idx, item in df3_2.iterrows():\n","  article = cleaning(item.sentence)\n","  text_data.write(article)\n","text_data.close()"],"metadata":{"id":"fGlq4hVvqkdK","executionInfo":{"status":"ok","timestamp":1686813854044,"user_tz":-540,"elapsed":5514,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":["# 3. 데이터 학습"],"metadata":{"id":"9lMyUzXOgU_Q"}},{"cell_type":"code","execution_count":66,"metadata":{"id":"3PXkmkvTJQZw","executionInfo":{"status":"ok","timestamp":1686809253062,"user_tz":-540,"elapsed":7756,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"gNtUeTbjJRBS","executionInfo":{"status":"ok","timestamp":1686809253062,"user_tz":-540,"elapsed":3,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}}},"outputs":[],"source":["def load_dataset(file_path, tokenizer, block_size = 128):\n","    dataset = TextDataset(\n","        tokenizer = tokenizer,\n","        file_path = file_path,\n","        block_size = block_size,\n","    )\n","    return dataset\n","\n","\n","def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer,\n","        mlm=mlm,\n","    )\n","    return data_collator\n","\n","\n","def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = load_dataset(train_file_path, tokenizer)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","\n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model()"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"W6O-HYS2JUYh","colab":{"base_uri":"https://localhost:8080/","height":169},"executionInfo":{"status":"ok","timestamp":1686812017778,"user_tz":-540,"elapsed":60200,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"6a8b2585-b85e-45ef-99a3-3475a215a120"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [160/160 00:46, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_delivery_pos.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_delivery_pos'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_delivery_neg.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_delivery_neg'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"CQ86xAQfsNhG","executionInfo":{"status":"ok","timestamp":1686812185787,"user_tz":-540,"elapsed":44476,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"0cfdc358-4227-4d1b-c424-51e3fa12a420"},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [110/110 00:32, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"_2ZohNVFfbnO","executionInfo":{"status":"ok","timestamp":1686812612846,"user_tz":-540,"elapsed":326343,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"ded0dd2b-e497-4102-e6aa-efce2033f26f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='990' max='990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [990/990 05:13, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.501100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_size_pos.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_size_pos'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_size_neg.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_size_neg'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"J7Z100Rfs831","executionInfo":{"status":"ok","timestamp":1686812839941,"user_tz":-540,"elapsed":213809,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"13c14ee3-7226-437b-c072-a4b204923233"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='627' max='627' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [627/627 03:20, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.583700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"8LgO89cyfbnP","executionInfo":{"status":"ok","timestamp":1686812971834,"user_tz":-540,"elapsed":131923,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"00802e8c-8675-4298-bd02-bc5544579ea4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [400/400 01:57, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_color_pos.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_color_pos'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_color_neg.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_color_neg'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"fx4dVGJLtaeV","executionInfo":{"status":"ok","timestamp":1686813070824,"user_tz":-540,"elapsed":99025,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"f8bbebda-7e87-4e64-b1aa-20d4c3e8deb2"},"execution_count":93,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [280/280 01:22, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"whKWVs0WfbnP","executionInfo":{"status":"ok","timestamp":1686813418480,"user_tz":-540,"elapsed":347704,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"644e8f19-8b24-4267-814f-633f2d83c4b2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1020/1020 05:30, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.769600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.540500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_quality_pos.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_quality_pos'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"code","source":["# you need to set parameters\n","train_file_path = \"/content/drive/MyDrive/TM/Data/GPT/TXT/Articles_quality_neg.txt\"\n","model_name = 'gpt2'\n","output_dir = '/content/drive/MyDrive/TM/Data/GPT/MODEL/Articles_quality_neg'\n","overwrite_output_dir = True\n","per_device_train_batch_size = 8\n","num_train_epochs = 1\n","save_steps = 500\n","\n","# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"eoyLgmrTtdCK","executionInfo":{"status":"ok","timestamp":1686814036283,"user_tz":-540,"elapsed":174558,"user":{"displayName":"별빛달빛","userId":"18148546629271062475"}},"outputId":"b8c3a974-5667-49d9-b316-69ec8ecf5923"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [510/510 02:38, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.781100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7rziNRuKAbj"},"outputs":[],"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXcfmjWnKB9I"},"outputs":[],"source":["def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","\n","def generate_text(sequence, max_length, path):\n","    model_path = path\n","    model = load_model(model_path)\n","    tokenizer = load_tokenizer(model_path)\n","    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.eos_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    return str(tokenizer.decode(final_outputs[0], skip_special_tokens=True))\n","\n","def extract_sentences(text):\n","    sentences = re.findall(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n","    return sentences\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhZYIeJNKG4W","outputId":"111e7135-2bf5-4047-9cf1-b5f19c07a54b"},"outputs":[{"name":"stdout","output_type":"stream","text":["배송, 사이즈, 색상, 퀄리티 중 선택하시오 : 배송\n"," \n","    - you got to choose. The price was excellent, I ordered a bottle which I had with me when it came out for sale, but I bought the bottle in the event this arrived.The package was super large, the delivery\n"," The price was excellent, I ordered a bottle which I had with me when it came out for sale, but I bought the bottle in the event this arrived.\n"]}],"source":["'''print(\"배송, 사이즈, 색상, 퀄리티 중 선택하시오 : \", end='')\n","path = input() #fine_tuned_gpt2_fahsion_delivery\n","sequence = input() # oil price\n","max_len = 50 #int(input()) # 20\n","if path == \"배송\":\n","    path = \"/fine_tuned_gpt2_fashion_delivery\"\n","elif path == \"사이즈\":\n","    path = \"/fine_tuned_gpt2_fashion_size\"\n","elif path == \"색상\":\n","    path = \"/fine_tuned_gpt2_fashion_color\"\n","else:\n","    path = \"/fine_tuned_gpt2_fashion_quality\"\n","res = generate_text(sequence, max_len, path)\n","print(res)\n","print(res.split(sep = '.')[1]+\".\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8GLZj5GfbnR"},"outputs":[],"source":["'''sequence = \"Good\"\n","max_len = 50\n","path = \"/fine_tuned_gpt2_fashion_delivery\"\n","temp = []\n","for i in range(300):\n","    res = generate_text(sequence, max_len, path)\n","    res = res.split(sep = '.')[1]+\".\"\n","    print(res)\n","    temp.append(res)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}